{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Installing Required Packages\n",
        "\n",
        "This code block uses pip install to install necessary Python libraries such as rdkit, pubchempy, admet_ai, thermo, and setuptools_rust. These packages are essential for cheminformatics tasks, PubChem API interaction, ADMET prediction, and thermochemical property calculations that will be performed later."
      ],
      "metadata": {
        "id": "972L3YUr6ixj"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d694ca30",
        "collapsed": true
      },
      "source": [
        "#%%capture\n",
        "!pip install rdkit\n",
        "!pip install pubchempy\n",
        "!pip install admet_ai\n",
        "!pip install thermo\n",
        "!pip install setuptools_rust"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Required Libraries and Helper Functions\n",
        "\n",
        "This block imports all the Python libraries required for the workflow, including os, time, logging, concurrent.futures, pandas, tqdm, rdkit, pubchempy, ADMETModel from admet_ai, and Joback from thermo. It also defines several helper functions:\n",
        "\n",
        "    get_matched_substructures_from_library: Identifies substructures from a library that match a query SMILES.\n",
        "    generate_transformation_product: Generates reaction products based on a reaction template and query SMILES.\n",
        "    generate_transformation_products_parallel: Parallelizes the product generation process for efficiency.\n",
        "    standardize_smiles_safe: Standardizes SMILES strings for consistent chemical representation.\n",
        "    get_cid_from_smiles_with_retry: Retrieves PubChem CIDs for SMILES with retry logic and caching.\n",
        "    compute_gibbs_free_energy: Calculates Gibbs free energy for a given SMILES.\n",
        "    run_ista_workflow: The main function that orchestrates the entire workflow, from matching substructures to predicting ADME properties and Gibbs free energy."
      ],
      "metadata": {
        "id": "vP4UvNIKUu3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import logging\n",
        "import concurrent.futures\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from typing import List, Dict, Any, Optional\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import rdChemReactions, DataStructs\n",
        "from rdkit import RDLogger\n",
        "RDLogger.DisableLog('rdApp.warning')\n",
        "RDLogger.DisableLog('rdApp.info')\n",
        "import pubchempy as pcp\n",
        "from admet_ai import ADMETModel\n",
        "from thermo import Joback\n",
        "\n",
        "\n",
        "# ----------------- HELPERS -----------------\n",
        "def get_matched_substructures_from_library(query_smiles: str, sub_struc_lib_df: pd.DataFrame, logger: logging.Logger) -> Optional[pd.DataFrame]:\n",
        "    if 'Fragmants Smarts' not in sub_struc_lib_df.columns:\n",
        "        logger.error(\"Input DataFrame must contain a 'Fragmants Smarts' column.\")\n",
        "        return None\n",
        "    query_molecule = Chem.MolFromSmiles(query_smiles)\n",
        "    if query_molecule is None:\n",
        "        logger.error(f\"Invalid query SMILES string: '{query_smiles}'\")\n",
        "        return None\n",
        "\n",
        "    smarts_patterns = sub_struc_lib_df['Fragmants Smarts'].apply(lambda x: str(x).strip('()')).tolist()\n",
        "    custom_fp = DataStructs.ExplicitBitVect(len(smarts_patterns))\n",
        "\n",
        "    for i, smarts in enumerate(smarts_patterns):\n",
        "        try:\n",
        "            pattern = Chem.MolFromSmarts(smarts)\n",
        "            if pattern is None:\n",
        "                continue\n",
        "            if query_molecule.HasSubstructMatch(pattern):\n",
        "                custom_fp.SetBit(i)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"SMARTS error at index {i}: {e}\", exc_info=True)\n",
        "\n",
        "    matched_indices = [i for i, bit_value in enumerate(custom_fp.ToList()) if bit_value == 1]\n",
        "    if not matched_indices:\n",
        "        return None\n",
        "\n",
        "    matched = sub_struc_lib_df.iloc[matched_indices].copy()\n",
        "    matched.rename(columns={'Smiles': 'matched_smiles'}, inplace=True)\n",
        "    matched['query_smiles'] = query_smiles\n",
        "    return matched\n",
        "\n",
        "\n",
        "def generate_transformation_product(trans_info: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
        "    results: List[Dict[str, Any]] = []\n",
        "    try:\n",
        "        query_smiles = trans_info['query_smiles']\n",
        "        match_smiles = trans_info['matched_smiles']\n",
        "        reac_template = trans_info['reac_temp']\n",
        "        reaction_smiles = trans_info['SANITIZED_MAPPED_REACTION']\n",
        "        rxn_id = trans_info['rxn_id']\n",
        "\n",
        "        updated_reactants = [\n",
        "            query_smiles if r == match_smiles else r\n",
        "            for r in reaction_smiles.split('>>')[0].split('.')\n",
        "        ]\n",
        "        reactant_mols = [Chem.MolFromSmiles(r) for r in updated_reactants]\n",
        "        if not all(reactant_mols):\n",
        "            return []\n",
        "\n",
        "        reaction = rdChemReactions.ReactionFromSmarts(reac_template)\n",
        "        if not reaction:\n",
        "            return []\n",
        "\n",
        "        products = reaction.RunReactants(reactant_mols)\n",
        "        unique_smiles_tuples = list({\n",
        "            tuple(Chem.MolToSmiles(mol, canonical=True) for mol in product_set if mol)\n",
        "            for product_set in products\n",
        "        })\n",
        "\n",
        "        for product_tuple in unique_smiles_tuples:\n",
        "            results.append({\n",
        "                'rxn_id': rxn_id,\n",
        "                'query_smiles': query_smiles,\n",
        "                'matched_smiles': match_smiles,\n",
        "                'sanitized_reaction': reaction_smiles,\n",
        "                'reaction_template': reac_template,\n",
        "                'transformed_products': product_tuple,\n",
        "                'rxn_smiles_with_query_cmpd': f\"{'.'.join(updated_reactants)}>>{'.'.join(product_tuple)}\"\n",
        "            })\n",
        "    except Exception:\n",
        "        return []\n",
        "    return results\n",
        "\n",
        "\n",
        "def generate_transformation_products_parallel(merged_info: pd.DataFrame, max_workers: int = 16) -> pd.DataFrame:\n",
        "    all_results: List[List[Dict[str, Any]]] = []\n",
        "    rows = merged_info.to_dict(orient=\"records\")\n",
        "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        futures = [executor.submit(generate_transformation_product, row) for row in rows]\n",
        "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing reactions\"):\n",
        "            result = future.result()\n",
        "            if result:\n",
        "                all_results.append(result)\n",
        "    return pd.DataFrame([item for sublist in all_results for item in sublist])\n",
        "\n",
        "\n",
        "def standardize_smiles_safe(smiles: str) -> Optional[str]:\n",
        "    from rdkit.Chem.MolStandardize import rdMolStandardize\n",
        "    try:\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        if mol is None:\n",
        "            return None\n",
        "        for atom in mol.GetAtoms():\n",
        "            atom.SetAtomMapNum(0)\n",
        "        mol = rdMolStandardize.Uncharger().uncharge(mol)\n",
        "        return Chem.MolToSmiles(mol, canonical=True)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "def get_cid_from_smiles_with_retry(smiles: str, max_retries: int = 5, initial_delay: float = 1.0, cache: Optional[Dict[str, Optional[str]]] = None) -> Optional[str]:\n",
        "    if smiles is None:\n",
        "        return None\n",
        "    if cache is not None and smiles in cache:\n",
        "        return cache[smiles]\n",
        "    delay = initial_delay\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            compounds = pcp.get_compounds(smiles, 'smiles')\n",
        "            if compounds:\n",
        "                cid = str(compounds[0].cid)\n",
        "                if cache is not None:\n",
        "                    cache[smiles] = cid\n",
        "                return cid\n",
        "            if cache is not None:\n",
        "                cache[smiles] = None\n",
        "            return None\n",
        "        except pcp.PubChemHTTPError as e:\n",
        "            if 'ServerBusy' in str(e) or 'PUGREST.ServerBusy' in str(e):\n",
        "                if attempt < max_retries - 1:\n",
        "                    time.sleep(delay); delay *= 2\n",
        "                else:\n",
        "                    if cache is not None:\n",
        "                        cache[smiles] = None\n",
        "                    return None\n",
        "            else:\n",
        "                if cache is not None:\n",
        "                    cache[smiles] = None\n",
        "                return None\n",
        "        except Exception:\n",
        "            if cache is not None:\n",
        "                cache[smiles] = None\n",
        "            return None\n",
        "    return None\n",
        "\n",
        "\n",
        "def compute_gibbs_free_energy(smiles: str, temp_k: float = 298.15):\n",
        "    if smiles is None or str(smiles).strip() == '':\n",
        "        return 'Invalid SMILES'\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        return 'Failed To Generate Rdkit Mol Object From Smiles'\n",
        "    try:\n",
        "        result = Joback(mol).estimate()\n",
        "        enthalpy = result['Hf'] / 1000\n",
        "        gibbs = result['Gf'] / 1000\n",
        "        entropy = (enthalpy - gibbs) / temp_k\n",
        "        stability = \"Highly Stable\" if gibbs < -100 else \"Stable\" if gibbs < 0 else \"Unstable / Highly Reactive\"\n",
        "        return {'Enthalpy': round(enthalpy, 2), 'Entropy': round(entropy, 4), 'Gibbs Free Energy': round(gibbs, 2), 'Stability': stability}\n",
        "    except Exception as e:\n",
        "        return {'Enthalpy': None, 'Entropy': None, 'Gibbs Free Energy': None, 'Stability': f'Error: {str(e)}'}\n",
        "\n",
        "\n",
        "# ----------------- MAIN WORKFLOW -----------------\n",
        "def run_ista_workflow(\n",
        "    query_smiles_list: List[str],\n",
        "    output_dir: str,\n",
        "    substructure_lib_path: str,\n",
        "    info_df_path: str,\n",
        "    log_file: str,\n",
        "):\n",
        "    os.makedirs(os.path.dirname(log_file), exist_ok=True)\n",
        "    logging.basicConfig(\n",
        "        level=logging.INFO,\n",
        "        format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
        "        handlers=[logging.FileHandler(log_file), logging.StreamHandler()]\n",
        "    )\n",
        "    logger = logging.getLogger(__name__)\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    sub_struc_lib = pd.read_csv(substructure_lib_path)\n",
        "    info_df = pd.read_csv(info_df_path)\n",
        "\n",
        "    model = ADMETModel()\n",
        "    cid_cache: Dict[str, Optional[str]] = {}\n",
        "\n",
        "    for index, query_smiles in enumerate(tqdm(query_smiles_list, desc=\"Query compounds\"), start=1):\n",
        "        matched_substruc_df = get_matched_substructures_from_library(query_smiles, sub_struc_lib, logger)\n",
        "        if matched_substruc_df is None or matched_substruc_df.empty:\n",
        "            continue\n",
        "\n",
        "        merged_info = pd.merge(\n",
        "            matched_substruc_df,\n",
        "            info_df[['RXN_ID', 'SANITIZED_MAPPED_REACTION', 'reac_temp']],\n",
        "            left_on='rxn_id',\n",
        "            right_on='RXN_ID',\n",
        "            how='inner'\n",
        "        ).drop(columns=['RXN_ID'])\n",
        "\n",
        "        result = pd.DataFrame(generate_transformation_products_parallel(merged_info, max_workers=16))\n",
        "        if result.empty:\n",
        "            continue\n",
        "\n",
        "        # Add standardized transformed products\n",
        "        result[\"standardized_transformed_products\"] = result[\"transformed_products\"].apply(\n",
        "            lambda tup: [s for s in (standardize_smiles_safe(x) for x in tup) if s]\n",
        "        )\n",
        "\n",
        "        subdir = os.path.join(output_dir, f'query_cmpd_{index}')\n",
        "        os.makedirs(subdir, exist_ok=True)\n",
        "        result.to_csv(os.path.join(subdir, f'query_compound_{index}_transformation_products.csv'), index=False)\n",
        "\n",
        "        # ADME table (products only)\n",
        "        unique_product_smiles = sorted({p for tup in result[\"standardized_transformed_products\"] for p in tup if p})\n",
        "        adme_prop = []\n",
        "        for smi in unique_product_smiles:\n",
        "            try:\n",
        "                pred = model.predict(smi)\n",
        "                pred['smiles'] = smi\n",
        "                adme_prop.append(pred)\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error predicting ADME properties for SMILES {smi}: {e}\")\n",
        "\n",
        "        adme_prop_df = pd.DataFrame(adme_prop)\n",
        "        adme_prop_df['Parent Compound/Product'] = 'Product'\n",
        "        adme_prop_query = pd.DataFrame([{**model.predict(query_smiles), 'smiles': query_smiles, 'Parent Compound/Product': 'Parent Compound'}])\n",
        "        adme_table = pd.concat([adme_prop_query, adme_prop_df], ignore_index=True)\n",
        "\n",
        "        column_order = ['Parent Compound/Product', 'smiles']\n",
        "        remaining_cols = [col for col in adme_table.columns if col not in column_order]\n",
        "        adme_table = adme_table[column_order + remaining_cols]\n",
        "\n",
        "        adme_table.to_csv(os.path.join(subdir, f'adme_properties_query_compound_{index}.csv'), index=False)\n",
        "\n",
        "        # Gibbs free energy (products only)\n",
        "        gibbs_rows = []\n",
        "        for smi in unique_product_smiles:\n",
        "            energy_result = compute_gibbs_free_energy(smi)\n",
        "            if isinstance(energy_result, dict):\n",
        "                gibbs_rows.append({\"standardized_smiles\": smi, **energy_result})\n",
        "            elif isinstance(energy_result, (int, float)):\n",
        "                gibbs_rows.append({\"standardized_smiles\": smi, \"Gibbs_Free_Energy\": energy_result})\n",
        "            else:\n",
        "                gibbs_rows.append({\"standardized_smiles\": smi, \"error\": str(energy_result)})\n",
        "\n",
        "        gibbs_df = pd.DataFrame(gibbs_rows)\n",
        "        if 'Gibbs_Free_Energy' in gibbs_df.columns:\n",
        "            gibbs_df['rank'] = gibbs_df['Gibbs_Free_Energy'].rank(ascending=True, method='min')\n",
        "        elif 'Gibbs Free Energy' in gibbs_df.columns:\n",
        "            gibbs_df['rank'] = gibbs_df['Gibbs Free Energy'].rank(ascending=True, method='min')\n",
        "\n",
        "        gibbs_df.to_csv(os.path.join(subdir, f'query_compound_{index}_gibbs_free_energy.csv'), index=False)\n",
        "\n",
        "        # Combined per-query result table\n",
        "        std_products_df = pd.DataFrame({\"standardized_smiles\": unique_product_smiles})\n",
        "\n",
        "        adme_products = adme_prop_df.copy()\n",
        "        adme_products = adme_products.rename(columns={\"smiles\": \"standardized_smiles\"})\n",
        "\n",
        "        # add CID for standardized products\n",
        "        adme_products[\"cid\"] = adme_products[\"standardized_smiles\"].apply(\n",
        "            lambda s: get_cid_from_smiles_with_retry(s, cache=cid_cache)\n",
        "        )\n",
        "\n",
        "        per_query_result = (\n",
        "            std_products_df\n",
        "            .merge(adme_products, on=\"standardized_smiles\", how=\"left\")\n",
        "            .merge(gibbs_df, on=\"standardized_smiles\", how=\"left\")\n",
        "        )\n",
        "\n",
        "        per_query_result.to_csv(\n",
        "            os.path.join(subdir, f\"query_compound_{index}_results_table.csv\"),\n",
        "            index=False\n",
        "        )\n"
      ],
      "metadata": {
        "id": "AsoYLW3PsKE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preparation and Execution\n",
        "\n",
        "This block performs initial setup by creating directories for storing results and source files. It then downloads two critical CSV files from Zenodo: Table_2_Chemical_Reaction_Analysis.csv (containing reaction information) and Table_3_Substructure_Library.csv (the library of substructures). These files are fundamental inputs for the run_ista_workflow function."
      ],
      "metadata": {
        "id": "Mo6VD4ulV1h7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/ista_results', exist_ok= True)\n",
        "os.makedirs('/content/ista_results/source_files', exist_ok= True)\n",
        "\n",
        "!wget -O /content/ista_results/source_files/Table_2_Chemical_Reaction_Analysis.csv https://zenodo.org/records/17576138/files/Table%202_Chemical%20Reaction%20Analysis.csv?download=1\n",
        "!wget -O /content/ista_results/source_files/Table_3_Substructure_Library.csv https://zenodo.org/records/17576138/files/Table%203_Substructure%20Library.csv?download=1"
      ],
      "metadata": {
        "collapsed": true,
        "id": "s_IJi8clLheu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Setting up File Paths\n",
        "\n",
        " This block defines the file paths for the log file, output directory, substructure library, and reaction information DataFrame. These variables are used as arguments when calling the run_ista_workflow function, ensuring that all outputs are saved in an organized manner."
      ],
      "metadata": {
        "id": "o9Kgwm_6WE_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_file= '/content/ista_results/ista_workflow/log/log_file'\n",
        "output_dir= '/content/ista_results/ista_workflow/output'\n",
        "substructure_lib_path= '/content/ista_results/source_files/Table_3_Substructure_Library.csv'\n",
        "info_df_path= '/content/ista_results/source_files/Table_2_Chemical_Reaction_Analysis.csv'"
      ],
      "metadata": {
        "id": "2i9da3YOSERI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the ISTA Workflow (cell ID: z65Zfy7TK31m)\n",
        "\n",
        "This final block initializes query_smiles_list with a single SMILES string ('CC(=O)Nc1ccc(O)cc1') which is Acetaminophen, and then calls the main run_ista_workflow function with all the predefined parameters. This initiates the entire process of identifying potential transformations, generating products, and calculating their ADME properties and Gibbs free energies."
      ],
      "metadata": {
        "id": "6ypEoXX4WUSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_smiles_list= ['CC(=O)Nc1ccc(O)cc1']\n",
        "\n",
        "\n",
        "run_ista_workflow(\n",
        "    query_smiles_list=query_smiles_list,\n",
        "    output_dir=output_dir,\n",
        "    substructure_lib_path=substructure_lib_path,\n",
        "    info_df_path=info_df_path,\n",
        "    log_file=log_file,\n",
        ")"
      ],
      "metadata": {
        "id": "z65Zfy7TK31m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}